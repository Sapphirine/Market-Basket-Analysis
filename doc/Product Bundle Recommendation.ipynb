{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Product Bundle Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Idea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It usually happens that some products are more often bought together than others. For example, milk and yoghurt, bananas and strawberries. Wouldn't it be great if we can use the product bundles to predict which product customers will buy next? Once a customer adds one product to cart, we will offer a list of recommended products to be bought together. The customer might then choose some products from the recommendation list. \n",
    "\n",
    "If we can predict the right product bundles and offer relevant recommendation, we can help customers find the right products meanwhile boost sales and profits.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solve this problem, we need at least these two steps:\n",
    " 1. Find out which products are frequently bought together\n",
    " 2. Given the previous product, generate a recommendation list, and predict the next product to be bought."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\n",
    "For the first step, we will use [bigram](https://en.wikipedia.org/wiki/Bigram) and count bigram frequency. A bigram is  a sequence of two adjacent elements from a string of tokens. In our case, a bigram will be the names of two products that are bought one after another.**\n",
    "\n",
    "For example, if a customer adds 'apple', 'banana', 'strawberry' to cart one by one, the bigrams will be \n",
    "\n",
    "    'apple banana', 'banana strawberry'. \n",
    "    \n",
    "Another customer adds 'banana', 'strawberry', 'milk', then the bigrams will be \n",
    "\n",
    "    'banana strawberry', 'strawberry milk'.\n",
    "\n",
    "After getting all bigrams, we will count how many times each bigram appear. \n",
    "\n",
    "The results of bigram frequency will be cleaned into a nested dictionary. The first layer key is the first product name, and first layer value is another dictionary. The second layer keys are all second product names, and second layer values are the frequency of each first-product-second-product bigram.\n",
    "\n",
    "If we still use the example above, the final dictionary will be:\n",
    "\n",
    "    {'apple': {'banana': 1}, 'banana': {'strawberry': 2}, {'strawberry': {'milk': 1}}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For the second step, we will give recommendation based on the bigram frequency.**\n",
    "\n",
    "To do this, we first sort the frequencies for each bigram in decreasing order.\n",
    "\n",
    "For example, if we have {'apple': {'strawberry': 5, 'avocado':5, 'banana': 7, 'milk': 1}}, it will be sorted as\n",
    "\n",
    "    'apple'+'banana': 7\n",
    "    'apple'+'avocado': 5\n",
    "    'apple'+'strawberry': 5\n",
    "    'apple'+'milk': 1\n",
    "    \n",
    "Next, we specify how many products we want to recommend. We use the parameter $k$ to denote the numbers.\n",
    "\n",
    "Then, we pick which products are in recommendation list. We'll start from the ones with highest frequency. But there are several situations we might need to take care of."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 1.What if there are several bigrams with the same frequency? \n",
    "   \n",
    "    The answer to this depend on the number of recommendation $k$. \n",
    "  \n",
    "   For example, if we still use the case above, now we have 'apple'+'avocado' and 'apple'+'strawberry' the same frequency. \n",
    "   If $k=3$, we will just pick both. If $k=2$, then we will randomly pick one out of these two bundles and add to list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 2.What if $k$ is to large and I don't have enough combinations to recommend?\n",
    "   \n",
    "   For example, if $k=10$, but in this case we only have 4 products that are ever bought together with 'apple'. We will first add all four products to recommendation list. But we still have 6 positions left. So we will start with one step further recommendation of one with highest frequency, that is to say, we will first see what can be bought together with 'banana'. If still more positions left, we will move to 'avocado', then 'strawberry', then 'milk'. If after all iterations, there are still more positions left, we will let it be that way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "Order_Products_Prior_DF = pd.read_csv('../data/order_products_prior.csv')\n",
    "ordersDF = pd.read_csv('../data/orders.csv')\n",
    "productsDF = pd.read_csv('../data/products.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Organic Egg Whites'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# orders in prior merged with product names\n",
    "Order_Product_Name_Prior = pd.merge(Order_Products_Prior_DF, \n",
    "                                    productsDF, how='left', on='product_id')\n",
    "# Prior orders with user_id, product_id, product_name\n",
    "Prior_User_Order_Product = pd.merge(Order_Product_Name_Prior, \n",
    "                                    ordersDF, how='left', on='order_id')\n",
    "\n",
    "Prior_User_Order_Product['product_name'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the product name is a string seperated with whitespace. We want to replace all whitespace with underscore \"_\", so that each product name is actually one word with no space in between."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products = Prior_User_Order_Product['product_name']\n",
    "product_no_space = []\n",
    "for product in products:\n",
    "    product = product.replace(\" \", \"_\")\n",
    "    product_no_space.append(product)\n",
    "\n",
    "# drop original column, replace it with one with no space\n",
    "Prior_User_Order_Product.drop(['product_name'], axis=1)\n",
    "Prior_User_Order_Product['product_name'] = product_no_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to have a dataframe with each row correspons to one order. The first column is each order_id. The second column is the names of all products correspond to each order_id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add product name to each user\n",
    "name_list = []\n",
    "for p_name in Prior_User_Order_Product.groupby('order_id')['product_name']:\n",
    "    name_list.append(' '.join(p_name[1]))\n",
    "    \n",
    "order_id = Prior_User_Order_Product.groupby('order_id')['product_name'].agg('count').index\n",
    "order_products = pd.DataFrame({'order_id':order_id, 'products':name_list})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a glimpse of our dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>products</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Organic_Egg_Whites Michigan_Organic_Kale Garli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Total_2%_with_Strawberry_Lowfat_Greek_Strained...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Plain_Pre-Sliced_Bagels Honey/Lemon_Cough_Drop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Bag_of_Organic_Bananas Just_Crisp,_Parmesan Fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Cleanse Dryer_Sheets_Geranium_Scent Clean_Day_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_id                                           products\n",
       "0         2  Organic_Egg_Whites Michigan_Organic_Kale Garli...\n",
       "1         3  Total_2%_with_Strawberry_Lowfat_Greek_Strained...\n",
       "2         4  Plain_Pre-Sliced_Bagels Honey/Lemon_Cough_Drop...\n",
       "3         5  Bag_of_Organic_Bananas Just_Crisp,_Parmesan Fr...\n",
       "4         6  Cleanse Dryer_Sheets_Geranium_Scent Clean_Day_..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_products.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we are going to use PySpark to extract bigrams, we need to prepare the dataframe in a format required by PySpark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataFrameList = []\n",
    "index = 0\n",
    "for row in order_products['products']:\n",
    "    productsName = row.split(' ')\n",
    "    tup = (index, productsName)\n",
    "    dataFrameList.append(tup)\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the data into train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# randomly split data into train (70%) and test (30%)\n",
    "import random\n",
    "import numpy\n",
    "random.shuffle(dataFrameList)\n",
    "\n",
    "train_data = dataFrameList[:2250411]\n",
    "test_data = dataFrameList[2250411:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use PySpark to Extract Bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First convert the data to spark dataframe. To reduce computation, we will read 10000 lines each time, and then combine all into one spark dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import Word2Vec\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Bigram\").getOrCreate()\n",
    "\n",
    "# spark dataframeï¼š read in batch of 10000 due to large computation\n",
    "N = len(train_data)//10000\n",
    "mod = len(train_data) % 10000\n",
    "trainDF = spark.createDataFrame(dataFrameList[0:10000], ['id',\"product_name\"])\n",
    "\n",
    "for i in range(1,N):\n",
    "    trainDF_sub = spark.createDataFrame(train_data[10000*i:10000*(i+1)], ['id',\"product_name\"])\n",
    "    traintDF = trainDF.union(trainDF_sub)\n",
    "    \n",
    "trainDF_sub = spark.createDataFrame(train_data[10000*N:len(train_data)], ['id',\"product_name\"])\n",
    "trainDF = trainDF.union(trainDF_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then train bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(id=3072566, product_name=['Twelve_Essentials_Fruit_and_Vegetable_Juice', 'Juice,_Vegetable_&_Fruit,_Fuel', 'Juice,_Vegetable_&_Fruit,_Purify'], bigrams=['Twelve_Essentials_Fruit_and_Vegetable_Juice Juice,_Vegetable_&_Fruit,_Fuel', 'Juice,_Vegetable_&_Fruit,_Fuel Juice,_Vegetable_&_Fruit,_Purify'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get bigram\n",
    "from pyspark.ml.feature import NGram\n",
    "\n",
    "ngram = NGram(n=2, inputCol=\"product_name\", outputCol=\"bigrams\")\n",
    "ngramDataFrame = ngram.transform(trainDF)\n",
    "\n",
    "ngramDataFrame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, after we got the bigrams, we start counting the frequency of each.\n",
    "\n",
    "Bigrams are stored in a nested dictionary:\n",
    "+ first layer key is the first word in a bigram \n",
    "+ second layer key is the second word in a bigram\n",
    "+ the second layer value is the frequency. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# count frequency:\n",
    "# Bigrams are stored in a nested dictionary:\n",
    "# first layer key is the first word in a bigram \n",
    "# second layer key is the second word in a bigram\n",
    "# the second layer value is the frequency. \n",
    "# {'Organic_Mint_Bunch': {'Organic_Navel_Orange':2, 'c':2}}\n",
    "\n",
    "bigrams = ngramDataFrame.toPandas()['bigrams']\n",
    "table = {}\n",
    "total = len(bigrams)\n",
    "completion = 0\n",
    "for bigram in bigrams:\n",
    "    for combination in bigram:\n",
    "        components = combination.split(' ')\n",
    "        key = components[0]\n",
    "        valKey = components[1]\n",
    "        if key in table:\n",
    "            valueDict = table[key]\n",
    "            if valKey in valueDict:\n",
    "                valueDict[valKey] = valueDict[valKey] + 1\n",
    "            else:\n",
    "                valueDict[valKey] = 1\n",
    "        else:\n",
    "            # create new value for key\n",
    "            valueDict =  {valKey: 1}\n",
    "            table[key] = valueDict\n",
    "    completion += 1\n",
    "#     print(\"==>\", float(completion / total) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see which combination appears more than 20 times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Organic_Hass_Avocado  +  Bag_of_Organic_Bananas :  26\n",
      "Banana  +  Organic_Avocado :  36\n",
      "Banana  +  Organic_Fuji_Apple :  25\n",
      "Banana  +  Honeycrisp_Apple :  23\n",
      "Banana  +  Organic_Strawberries :  27\n",
      "Bag_of_Organic_Bananas  +  Organic_Strawberries :  31\n",
      "Bag_of_Organic_Bananas  +  Organic_Hass_Avocado :  30\n",
      "Bag_of_Organic_Bananas  +  Organic_Baby_Spinach :  23\n",
      "Organic_Avocado  +  Banana :  22\n",
      "Large_Lemon  +  Limes :  24\n"
     ]
    }
   ],
   "source": [
    "for firstWord in table:\n",
    "    for secondWord in table[firstWord]:\n",
    "        if table[firstWord][secondWord] > 20:\n",
    "            print(firstWord, \" + \", secondWord, \": \", table[firstWord][secondWord])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part will use the frequencies above to generate recommendations for each product. We define functions to realize this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getPureData(prodName):\n",
    "    \n",
    "    '''sort the bigram frequencies in descending order, \n",
    "       then return merely the corresponding product names in the same order'''\n",
    "    \n",
    "    if prodName not in table:\n",
    "        return []\n",
    "    sortedOringalList = sorted(table[prodName].items(), key=lambda x: x[1], reverse=True)\n",
    "#     print(sortedOringalList)\n",
    "    data = {}\n",
    "    for tp in sortedOringalList:\n",
    "        product = tp[0]\n",
    "        number = tp[1]\n",
    "        if number in data:\n",
    "            productList = data[number]\n",
    "            productList.append(product)\n",
    "        else:\n",
    "            productList = [product]\n",
    "        data[number] = productList\n",
    "#     print(data)\n",
    "#     print(\"==> Get pure data name:\")\n",
    "    pureData = data.values()\n",
    "#     print(pureData)\n",
    "    return list(pureData)\n",
    "\n",
    "def pickRecommendProds(pureData, numberOfRecommend):\n",
    "    \n",
    "    '''Pick certain number of products from the sorted product names'''\n",
    "    \n",
    "    recommendProds = []\n",
    "    for prods in pureData:\n",
    "        if len(prods) <= numberOfRecommend:\n",
    "            recommendProds += prods\n",
    "            numberOfRecommend -= len(prods)\n",
    "        else:\n",
    "            recommendProds += random.sample(prods, numberOfRecommend)\n",
    "            numberOfRecommend = 0\n",
    "\n",
    "        if numberOfRecommend == 0:\n",
    "            break\n",
    "    \n",
    "    return recommendProds\n",
    "\n",
    "# recommend products bought together with 'name'\n",
    "# name: the product to start with\n",
    "def getRecommend(name, numberOfRecommend):\n",
    "    \n",
    "    '''Recommend certain number of products bought after the given input name'''\n",
    "    \n",
    "    # numberOfRecommend = 10\n",
    "    recommendProducts = []\n",
    "    productName = name\n",
    "    index = 0\n",
    "\n",
    "    while (numberOfRecommend):\n",
    "#         print(\"->Target: \", productName)\n",
    "#         print(\"->numberOfRecommend: \", numberOfRecommend)\n",
    "#         print(\"->Index: \", index)\n",
    "        data = getPureData(productName)\n",
    "    #     print(\"Pure data:\", data)\n",
    "        intermediate = pickRecommendProds(data, numberOfRecommend)\n",
    "        recommendProducts += intermediate\n",
    "#         print(\"Recommend: \", recommendProducts)\n",
    "#         print(\"Recommend: \", recommendProducts)\n",
    "        if len(intermediate) == 0 and index == len(recommendProducts):\n",
    "            break\n",
    "        numberOfRecommend -= len(intermediate)\n",
    "        if numberOfRecommend > 0:\n",
    "#             print(\"Still left: \", numberOfRecommend)\n",
    "            productName = recommendProducts[index]\n",
    "            index += 1\n",
    "\n",
    "#         print(\"==================\")\n",
    "\n",
    "    return recommendProducts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try an example: 15 Products recommended after \"Organic_Mint_Bunch\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Organic_Italian_Parsley_Bunch', 'Garlic', 'Organic_Carrot_Bunch', 'Fresh_Cauliflower', 'Organic_Cilantro', 'Organic_Baby_Spinach_Salad', 'Organic_Cilantro_Bunch', 'Organic_Thyme', '100%_Pressed_Apple__Fruit_Juice', 'Organic_Mountain_Forest_Honey_Light_Amber', 'Organic_Cilantro', 'Large_Lemon', 'Organic_Mint', 'Organic_Basil', 'Organic_Garlic']\n"
     ]
    }
   ],
   "source": [
    "print(getRecommend(\"Organic_Mint_Bunch\", 15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see how it performs on test data.\n",
    "\n",
    "We evaluate it by seeing in each order, how many products bought are in recommend list.\n",
    "\n",
    "For example, test_order_1 in test data contains 10 products.\n",
    "\n",
    "We start by recommend what can be bought with the first product, and we will give 10 recommendations (which is of same size as the actual order). We compare the next 9 actually bought products with this 10 recommendations. If there's a match, we will add 1 to the total score. Then we move to the second actually bought product, and give another 10 recommendations bought with the second product. Compare again, and compute total scores. ... After iterate through all actually bought products in this order, we have the total score, and divide the score by the order size to get the final_score_1 for test order 1.\n",
    "\n",
    "We save all final scores in one list and compute the average score in the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def TestScore(test_data):\n",
    "    \n",
    "    scores = []\n",
    "\n",
    "    for order_info in test_data:\n",
    "        this_order = order_info[1]\n",
    "        order_len = len(this_order)\n",
    "        #print('order:', this_order)\n",
    "        #print('length of order', order_len)\n",
    "        i = 0\n",
    "        this_score = 0\n",
    "\n",
    "        while (i < order_len):\n",
    "            if this_order[i] in table:\n",
    "                # use original order length as the num of recommendation\n",
    "                recommends = getRecommend(this_order[i], order_len)\n",
    "                #print('====> recommends of ', this_order[i], \" : \", recommends)\n",
    "                laterProds = this_order[i:]\n",
    "                # check if the recommended products is included in order\n",
    "                for prod in laterProds:\n",
    "                    if prod in recommends:\n",
    "                        #print(\"-->\", prod)\n",
    "                        this_score += 1\n",
    "                i += 1\n",
    "            else:\n",
    "                # if the product is not trained in model, skip\n",
    "                i += 1\n",
    "                order_len -= 1\n",
    "\n",
    "        #print(this_score)\n",
    "        if not order_len == 0:\n",
    "            scores.append(this_score/order_len)\n",
    "        #print(scores)\n",
    "        \n",
    "    # return a list of predicted scores\n",
    "    return(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======> Mean Test Scores:  0.182374730607\n"
     ]
    }
   ],
   "source": [
    "scores = TestScore(test_data)\n",
    "print(\"======> Mean Test Scores: \", numpy.mean(scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
